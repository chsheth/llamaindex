{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "\n",
    "Typical challenges without RAG\n",
    "1. LLM depend on last update\n",
    "2. Factual errors\n",
    "3. Might not have the context\n",
    "\n",
    "So its needed to include knowledge\n",
    "1. Fine Tuning\n",
    "-- pretrained + last layer retrained using proprietary data\n",
    "-- expensive\n",
    "-- needs expertise\n",
    "\n",
    "2. In context learning\n",
    "-- using prompts to give context and examples\n",
    "-- max tokens limit\n",
    "-- needs memory for permanent session storage\n",
    "\n",
    "\n",
    "3. RAG\n",
    "-- LLM + Info Retrieval\n",
    "-- load docs\n",
    "- indexing & storage\n",
    "-- create chunk -> managing size\n",
    "-- embeddings -> numeric tranformation of each chunk\n",
    "-- indexing -> helps with efficient retrieval\n",
    "-- create a vector store -> storage of this information with efficient retrieval\n",
    "-- retrieves info -> get the right answer by taking the user query, embedding it, matching with vector store to get context, and then fetching the top k response back, these are then used to create the prompt for the LLM\n",
    "-- synthesize the response -> top k relevant chunks + context + user query is passed to LLM and get an answer  \n",
    "-- query engine -> provide output through generator LLM\n",
    "-- evaluation\n",
    "\n",
    "\n",
    "## RAG Notes\n",
    "\n",
    "### RAG\n",
    "Data comes from \n",
    "-- API\n",
    "-- Raw file\n",
    "-- Vector store\n",
    "-- Database\n",
    "\n",
    "Needs \n",
    "-- framework like Llamanindex or Langchain\n",
    "-- embedding models\n",
    "-- vector store\n",
    "-- LLM\n",
    "\n",
    "### Llamanindex\n",
    "-- single framework to build LLM search + retrieval (Q&A) type applications\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "#STEPS\n",
    "#1. Ingest\n",
    "#2. Index\n",
    "#3. Retrieve\n",
    "#4. REsponse Systhesizer\n",
    "#5. Ouery\n",
    "'''\n",
    "%%capture\n",
    "\n",
    "!pip install llama-index\n",
    "!pip install python-dotenv\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv(r'C:\\Users\\myohollc\\Documents\\llamaindex\\av_RAG_LlamaIndex\\.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key loaded\n",
      "key loaded\n"
     ]
    }
   ],
   "source": [
    "if GOOGLE_API_KEY=='':\n",
    "    print('key not loaded')\n",
    "else:\n",
    "    print('key loaded')\n",
    "\n",
    "if OPENAI_API_KEY=='':\n",
    "    print('key not loaded')\n",
    "else:\n",
    "    print('key loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=[\"./data/transformers.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 117276a3-f08f-4df0-9dec-f83113e3b303\n",
      "Text: Provided proper attribution is provided, Google hereby grants\n",
      "permission to reproduce the tables and figures in this paper solely\n",
      "for use in journalistic or scholarly works. Attention Is All You Need\n",
      "Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google\n",
      "Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com\n",
      "Jakob Usz...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'page_label': '1',\n",
       " 'file_name': 'transformers.pdf',\n",
       " 'file_path': 'data\\\\transformers.pdf',\n",
       " 'file_type': 'application/pdf',\n",
       " 'file_size': 2215244,\n",
       " 'creation_date': '2024-06-27',\n",
       " 'last_modified_date': '2025-02-15'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)\n",
    "documents[0]\n",
    "print(documents[0])\n",
    "documents[0].text\n",
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
